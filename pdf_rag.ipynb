{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f209562-5066-40f3-96fb-25ccf231e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import requests\n",
    "import tempfile\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1327f35c-527f-43f8-9a47-3e90188cee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-5-nano\"\n",
    "LLAMA_MODEL = \"llama3.1:8b\"\n",
    "EMBEDDING_MODEL = \"embeddinggemma\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2453465e-527a-4b65-a88b-21aeeb34b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f64151c9-20e5-43e1-8095-a817054a878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"data/sample-invoice.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61d5657d-f9f2-44ca-9f91-c24ba3cd0668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 3\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(f\"Total number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0c937c4-93ec-4e72-a59e-c7f7a44888c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\", encode_kwargs = {\"normalize_embeddings\": False})\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embeddings = OllamaEmbeddings(model=\"embeddinggemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ed39112-504c-44c1-b013-0847f10a1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f40360dc-cb02-4262-8b87-88da4ed7cf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 3 chunks.\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3972c56-5e03-4def-93ed-8d8ca02d6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.7, model_name=GPT_MODEL)\n",
    "llm = ChatOllama(temperature=0.7, model=LLAMA_MODEL,  validate_model_on_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e5700e8-0802-4b8f-9867-ed31a64fef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "887317f6-08d0-4e27-8962-88033e0a021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "213a9065-20e7-4fec-9ea7-0732cc648f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa46ecff-bd2d-41d5-b342-8cb04848bd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the requested details:\n",
      "\n",
      "1. **Invoice No**: 123100401\n",
      "2. **Customer No**: 12345\n",
      "3. **Invoice Period**: Not specified in the format \"01.02.2024 to 29.02.2024\"\n",
      "4. **Date**: 01.03.2024 (note: this is not a date range, but a specific date when the invoice was generated)\n",
      "5. **Gross Amount with VAT**: 453.53 €\n",
      "6. **Gross Amount without VAT**: 381.12 €\n"
     ]
    }
   ],
   "source": [
    "query = \"Fetch following details from the pdf: Invoice No, Customer No, Invoice Period, Date, Gross Amount with and without Vat.\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d77274d-0bce-4428-948d-25ed2a9e09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = None\n",
    "\n",
    "def load_pdf(file):\n",
    "    global conversation_chain\n",
    "    \n",
    "    file_path = file.name\n",
    "\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "\n",
    "    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "    if os.path.exists(db_name):\n",
    "        Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "    vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "\n",
    "    llm = ChatOllama(temperature=0.7, model=LLAMA_MODEL, validate_model_on_init=True)\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)\n",
    "\n",
    "    return \"✅ PDF uploaded and indexed. You can now ask questions!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1452b496-997d-4844-80b8-b47dca9e7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, memory):\n",
    "    global conversation_chain\n",
    "    \n",
    "    if conversation_chain is None:\n",
    "        return \"⚠️ Please upload a PDF first.\"\n",
    "\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0018b2b2-ccae-4c10-93cd-6fb618958ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Open Source PDF Extraction with QA Chatbot\")\n",
    "    pdf_upload = gr.File(label=\"Upload your PDF\", file_types=[\".pdf\"])\n",
    "    status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "    pdf_upload.change(load_pdf, inputs=pdf_upload, outputs=status)\n",
    "\n",
    "    gr.ChatInterface(\n",
    "        fn=chat,\n",
    "        type=\"messages\",\n",
    "        description=\"Ask questions about your uploaded PDF.\",\n",
    "    )\n",
    "\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d93836-1b91-4e29-8ebf-bf45f3851361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
